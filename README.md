# üè¢ Pipeline de Dados - CNPJs da Receita Federal

<div align="center">

![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)
![PySpark](https://img.shields.io/badge/PySpark-3.5-orange.svg)
![Delta Lake](https://img.shields.io/badge/Delta%20Lake-3.0-green.svg)
![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Pipeline completo de ETL para processamento dos dados p√∫blicos de CNPJs da Receita Federal, implementando a Medallion Architecture com PySpark e Delta Lake.

[Funcionalidades](#-funcionalidades) ‚Ä¢
[Arquitetura](#-arquitetura) ‚Ä¢
[Instala√ß√£o](#-instala√ß√£o) ‚Ä¢
[Uso](#-uso) ‚Ä¢
[Documenta√ß√£o](#-documenta√ß√£o)

</div>

---

## üìã Sobre o Projeto

Este projeto implementa um **pipeline de dados completo** para ingest√£o e processamento dos dados p√∫blicos de CNPJs da Receita Federal, disponibilizados em [dados.gov.br](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj).

### üéØ Objetivo

Criar uma solu√ß√£o robusta e escal√°vel que:

- Download autom√°tico dos dados da Receita Federal
- Processamento de milh√µes de registros de forma eficiente
- Valida√ß√µes e regras de neg√≥cio aplicadas
- Qualidade e governan√ßa de dados (LGPD)
- Dados tratados dispon√≠veis para consumo anal√≠tico e transacional

### üí° Contexto do Desafio

Desenvolvido como parte de um desafio t√©cnico para avaliar compet√™ncias em:

- Engenharia de dados e arquitetura de pipelines
- Processamento distribu√≠do com PySpark
- Modelagem de dados e Data Lakehouse
- Containeriza√ß√£o e orquestra√ß√£o de servi√ßos
- Boas pr√°ticas de desenvolvimento e documenta√ß√£o

---

## ‚ú® Funcionalidades

### Core Features

- **Download Autom√°tico**: Baixa arquivos .zip da Receita Federal com retry e valida√ß√£o
- **Processamento Distribu√≠do**: Utiliza PySpark para processar grandes volumes
- **Medallion Architecture**: Implementa√ß√£o completa (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold)
- **Delta Lake**: ACID transactions, time travel e schema evolution
- **SCD Type 2**: Rastreamento hist√≥rico de mudan√ßas em empresas
- **Conformidade LGPD**: Mascaramento autom√°tico de CPFs
- **Data Quality**: Valida√ß√µes, deduplica√ß√£o e quarentena de dados
- **OBT (One Big Table)**: Tabela final desnormalizada para an√°lise
- **PostgreSQL**: Persist√™ncia para aplica√ß√µes transacionais
- **Containeriza√ß√£o**: Ambiente completo com Docker Compose

### Features Avan√ßadas

- **Performance**: OPTIMIZE e Z-ORDERING no Delta Lake
- **Logging Estruturado**: Rastreabilidade completa do pipeline
- **Auditoria**: Tabelas de quarentena para an√°lise de dados rejeitados
- **FinOps**: Limpeza autom√°tica de arquivos intermedi√°rios

---

## üèóÔ∏è Arquitetura

![Diagrama do Pipeline de Dados](https://raw.githubusercontent.com/rafaelpds/receita-federal-cnpj/main/docs/pipeline_flow.png)

### Medallion Architecture

**RAW LAYER**
- Arquivos ZIP da Receita Federal
- Download autom√°tico via HTTP
- Armazenamento tempor√°rio

**BRONZE LAYER**
- Dados brutos em formato Delta Lake
- Schema enforcement
- Particionamento
- Sem transforma√ß√µes

**SILVER LAYER**
- Valida√ß√µes e limpeza de dados
- Deduplica√ß√£o
- Normaliza√ß√£o de campos
- SCD Type 2 para empresas (rastreamento hist√≥rico)
- Mascaramento LGPD (CPFs)
- OPTIMIZE com Z-ORDERING

**GOLD LAYER**
- Agrega√ß√µes e regras de neg√≥cio
- OBT (One Big Table) desnormalizada
- Apenas registros ativos (SCD Type 2)
- Persist√™ncia: Delta Lake + PostgreSQL

### SCD Type 2 - Slowly Changing Dimensions

A camada **Silver** implementa SCD Type 2 para a tabela de **empresas**, permitindo rastrear mudan√ßas hist√≥ricas:

**Colunas de Controle:**
- `data_inicio`: Quando o registro ficou ativo
- `data_fim`: Quando foi substitu√≠do (NULL = ativo)
- `ativo`: True = vers√£o atual, False = hist√≥rico
- `hash_chave`: Detecta mudan√ßas nos dados

**Exemplo de Hist√≥rico:**

| cnpj | razao_social | data_inicio | data_fim | ativo |
|------|--------------|-------------|----------|-------|
| 00000000 | BANCO DO BRASIL SA | 2025-01-01 10:00 | 2025-01-02 15:00 | False |
| 00000000 | BB LTDA | 2025-01-02 15:00 | NULL | True |

**Por que SCD Type 2?**
- Empresas mudam raz√£o social, capital social, porte
- Importante para auditorias e an√°lises temporais
- S√≥cios tem snapshot simples (n√£o precisam de hist√≥rico)

### Stack Tecnol√≥gica

**Processamento:**
- Python 3.10+
- PySpark 3.5.0
- Delta Lake 3.0.0

**Armazenamento:**
- Delta Lake (Data Lakehouse)
- PostgreSQL 15 (OLTP)

**Infraestrutura:**
- Docker & Docker Compose
- Ubuntu/Linux

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM m√≠nimo
- 20GB espa√ßo em disco

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/rafaelpds/receita-federal-cnpj.git
cd receita-federal-cnpj
```

### 2. Suba os Servi√ßos

```bash
docker-compose up
```

Isso ir√°:
- Construir a imagem Docker com PySpark e depend√™ncias
- Subir PostgreSQL
- Executar o pipeline automaticamente

### 3. Acompanhe os Logs

```bash
docker-compose logs -f cnpj_app
```

---

## üìä Uso

### Executar Pipeline Completo

```bash
docker-compose up
```

### Executar Camadas Individualmente

```bash
# Apenas Bronze
docker-compose run cnpj_app python -m pipelines.bronze_rf_cnpj

# Apenas Silver
docker-compose run cnpj_app python -m pipelines.silver_rf_cnpj

# Apenas Gold
docker-compose run cnpj_app python -m pipelines.gold_rf_cnpj
```

---

## üìÅ Estrutura do Projeto

```
receita-federal-cnpj/
‚îú‚îÄ‚îÄ data/                          # Dados persistidos (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ bronze/                    # Delta Lake - dados brutos
‚îÇ   ‚îú‚îÄ‚îÄ gold/                      # Delta Lake - dados agregados
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # Arquivos ZIP
‚îÇ   ‚îî‚îÄ‚îÄ silver/                    # Delta Lake - dados limpos
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_flow.png          # Diagrama da arquitetura
‚îú‚îÄ‚îÄ jars/                          # Depend√™ncias Java (Delta, PostgreSQL)
‚îú‚îÄ‚îÄ pipelines/
‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ bronze_rf_cnpj.py          # Ingest√£o de dados brutos
‚îÇ   ‚îú‚îÄ‚îÄ gold_rf_cnpj.py            # Agrega√ß√µes + regras de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ raw_rf_cnpj.py             # Download dos arquivos
‚îÇ   ‚îî‚îÄ‚îÄ silver_rf_cnpj.py          # Limpeza + SCD Type 2
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yml             # Orquestra√ß√£o de servi√ßos
‚îú‚îÄ‚îÄ main.py                        # Orquestrador principal
‚îú‚îÄ‚îÄ README.md                      # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python
```

---

## üìñ Documenta√ß√£o

### Camadas do Pipeline

#### Bronze Layer
- **Objetivo**: Ingest√£o de dados brutos sem transforma√ß√µes
- **Formato**: Delta Lake
- **Schema**: Preserva estrutura original dos CSVs
- **Valida√ß√µes**: Apenas schema enforcement

#### Silver Layer
- **Objetivo**: Dados limpos e validados
- **Transforma√ß√µes**:
  - Valida√ß√£o de CNPJs (8 d√≠gitos num√©ricos)
  - Normaliza√ß√£o de textos (UPPER, TRIM)
  - Deduplica√ß√£o
  - Mascaramento de CPFs (LGPD)
  - SCD Type 2 para empresas
- **Otimiza√ß√£o**: OPTIMIZE + Z-ORDERING por CNPJ

#### Gold Layer
- **Objetivo**: Tabela anal√≠tica (OBT)
- **Regras de Neg√≥cio**:
  - `qtde_socios`: COUNT de s√≥cios por CNPJ
  - `flag_socio_estrangeiro`: True se ‚â•1 s√≥cio estrangeiro
  - `doc_alvo`: True se cod_porte='03' E qtde_socios > 1
- **Destinos**: Delta Lake + PostgreSQL

### Schema dos Dados

**Empresas (Silver)**
```
cnpj: string
razao_social: string
natureza_juridica: int
qualificacao_responsavel: int
capital_social: float
cod_porte: string
hash_chave: string
data_inicio: timestamp
data_fim: timestamp
ativo: boolean
```

**S√≥cios (Silver)**
```
cnpj: string
tipo_socio: int
nome_socio: string
documento_socio: string (mascarado)
codigo_qualificacao_socio: string
is_estrangeiro: boolean
```

**Resultado Final (Gold)**
```
cnpj: string
qtde_socios: int
flag_socio_estrangeiro: boolean
doc_alvo: boolean
```

---

## üîß Configura√ß√µes

### Vari√°veis de Ambiente

Edite o `docker-compose.yml`:

```yaml
environment:
  - POSTGRES_HOST=postgres
  - POSTGRES_PORT=5432
  - POSTGRES_DB=cnpj_db
  - POSTGRES_USER=cnpj_user
  - POSTGRES_PASSWORD=cnpj_pass
```

### Ajustes de Performance

No `silver_rf_cnpj.py`:

```python
.config("spark.driver.memory", "2g")        # Mem√≥ria do driver
.config("spark.executor.memory", "2g")      # Mem√≥ria do executor
.config("spark.sql.shuffle.partitions", "4") # Paralelismo
```

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## üë§ Autor

**Rafael Santos**

- GitHub: [@rafaelpds](https://github.com/rafaelpds)
- LinkedIn: [Rafael Pereira](https://linkedin.com/in/rafaelpds)


---

<div align="center">

**Desenvolvido com ‚ù§Ô∏è para o desafio de Data Engineering**

</div>
